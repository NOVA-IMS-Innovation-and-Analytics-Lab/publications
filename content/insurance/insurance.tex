\documentclass[parskip=full]{scrartcl}

\pdfoutput=1

\title{G-SOMO \\ \LARGE{Oversampling for Insurance Data}}

\author{
	Fernando Bacao\(^{1*}\), Georgios Douzas\(^{1}\)
	\\
	\small{\(^{1}\)NOVA Information Management School, Universidade Nova de Lisboa}
	\\
	\small{*Corresponding Author: bacao@novaims.unl.pt}
	\\
	\\
	\small{Postal Address: NOVA Information Management School, Campus de Campolide, 1070-312 Lisboa, Portugal}
	\\
	\small{Telephone: +351 21 382 8610}
}

\usepackage{breakcites}
\usepackage{float}
\usepackage{graphicx}
\usepackage{geometry}
\geometry{
	a4paper,
	total={170mm,257mm},
	left=18mm,
	right=18mm,
	top=8mm,
}
\usepackage{amsmath}
\newcommand{\inlineeqnum}{\refstepcounter{equation}~~\mbox{(\theequation)}}
\usepackage{enumitem}
\usepackage[ruled,vlined]{algorithm2e}
\usepackage{booktabs}
\usepackage{pgfplotstable}
\usepackage{longtable}
\usepackage{tabu}
\usepackage{hyperref}
\date{}

\begin{document}

\maketitle

\begin{abstract}
Traditional supervised machine learning classifiers are challenged to learn
highly skewed data distributions as they are designed to expect classes to
equally contribute to the minimization of the classifiers cost function.
Moreover, the classifiers design expects equal misclassification costs, causing
a bias for underrepresented classes. Thus, different strategies to handle the
issue are proposed by researchers. The modification of the data set has become a
common practice since the procedure is generalizable to all classifiers. Various
algorithms to rebalance the data distribution through the creation of synthetic
instances were proposed in the past.  In this paper, we propose a new
oversampling algorithm named G-SOMO, a method that is adopted from our previous
research. The algorithm identifies optimal areas to create artificial data
instances in an informed manner and utilizes a geometric region during the data
generation to increase variability and to avoid correlation. In this paper we
use real world data from a Columbian insurance company, to investigate the
benefits of using oversampling to improve the quality of predictive machine
learning models. Our empirical results, validated with different classifiers and
metrics against a benchmark of commonly used oversampling methods show that
G-SOMO consistently outperforms competing oversampling methods.
\end{abstract}

\section{Introduction}

In recent years machine learning models have become pervasive in most economic
activities and human endeavors. The growing popularity of these models comes
mostly from the raising of two different but related trends: cheap computation
and huge amounts of data. This binomial created the opportunity to be more
accurate in problems where there is very limited theoretical knowledge.
Basically, machine learning harnesses the power of data and computing to produce
more accurate predictions. The use of machine learning models to assess and
predict different types of risks has become a common practice in most insurance
companies around the world, as these models have proved to be able to increased
accuracy in most risk related predictions tasks.

Being data a fundamental tenant of machine learning, its quality and
availability will obviously impact the quality of the final models. In many
situations the availability of data becomes the main problem in building
accurate and robust machine learning models. Although, in general we can say
that we live in a data-rich world there are still many domains and circumstances
characterized by data scarcity. In risk analysis a particular type of data
scarcity tends to be prevalent, resulting from the fact that it deals with
uncommon events; as a consequence datasets are usually highly skewed. Examples
of this range from assessment of financial credit risk to fraud detection, and
include forecasting future high-cost users of health care and bankruptcy
prediction models. It is safe to say that in order to successfully apply machine
learning algorithms to most risk assessment problems the user will be faced with
the need to solve, or at least mitigate, the negative effects of dataset
imbalance.

Building models with highly skewed datasets is usually known, in the machine
learning literature, as imbalanced learning. Imbalance learning is a pervasive
issue in risk analysis and assessment, as finding perfectly balanced datasets,
with 50\% examples of each class, is very rare. Imbalance learning constitutes a
significant obstacle when building accurate and robust predictive models. Skewed
datasets present an imbalance between the different classes represented. In
these cases, the datasets may even be very large, but they are characterized by
having a large number of data points of one class (majority class) and a very
small number of data points of the other class(es) (minority classes). This is
not an optimal situation, as the objective of a classification algorithm is to
learn a classifier that is able to discriminate the classes. Having a small
number of data points from one of the classes will make the learning task much
more challenging, eventually impossible. The ability to deal and mitigate the
imbalance learning problem constitutes an important skill for both practitioners
and researchers alike.

There are several options to deal with imbalanced learning, which can be broadly
classified into three main groups \cite{Fernandez2013}. One is the
modification or creation of algorithms that reinforce the learning towards the
minority class. Another approach relates with the application of cost-sensitive
methods to minimize higher cost errors. The last one consists in the
modification of the data, by re-balancing the class distribution, which is done
through the use of undersampling, oversampling or hybrid methods. This last
approach has some relevant advantages over the previous ones, especially in
terms of real world applications, where most users are usually not machine
learning experts, and thus not able to modify algorithms. Using dataset
re-balancing strategies simplifies the task and, once the dataset is balanced,
the user can use any “off-the-shelf” algorithm.

It is important to note that there are two different problems associated with
imbalanced learning. The first concerns the skewness of the distribution, in
other words, having a relative small number of positive samples when compared
with the number of negative samples. In this case we have what can be called
relative scarcity. The second relates to the case in which, besides this
imbalance, we also have a small number of positive samples in absolute terms.
While in the first case we may consider different strategies to approach the
problem, in the second case the only real option is oversampling. This paper
focuses on improvement of predictive machine learning models through the use of
oversampling techniques to deal with the imbalanced learning problem in the
context fraud identification. Identifying fraudulent behavior is relevant for
financial companies due to the disastrous consequences it brings with it. These
usually translate into economic losses, negative impact on its public image,
client’s forfeiture, among others. In Colombia, this situation constitutes an
important problem for insurance companies, as they are faced with significant
levels of fraud in compulsory auto insurance. Millions of dollars in losses
force companies to search for better methodologies to assertively respond to
this state of affairs, and better predictive models are amongst the most
promising tools to control this problem. In this paper we use real world data
from a Columbian insurance company, to investigate the benefits of using
oversampling to improve the quality of predictive machine learning models.

We will compare several oversampling methods, which are readily available for
use by practitioners and researchers in the risk analysis domain. The objective
is to understand the impact of these oversampling methods in the quality of the
machine learning models produced, understand which of the methods is the best
option and derive some practical guidelines for its application.

The rest of this paper is structured as follows: in section 3 a general review
related with oversampling techniques and imbalanced learning problem is
presented. In section 4 research methodology is explained followed by results
and discussion in section 5. Finally, conclusions and future work are expressed
on section 6.

\bibliography{references}
\bibliographystyle{apalike}

\end{document}