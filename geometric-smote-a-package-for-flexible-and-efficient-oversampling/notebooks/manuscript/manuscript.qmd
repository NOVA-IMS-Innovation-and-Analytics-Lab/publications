---
title: "geometric-smote: A package for flexible and efficient oversampling"
jupyter: python3
format: 
  pdf:
    keep-tex: true
author:
  - name: Georgios Douzas
    role:
      - Software
      - Methodology
      - Data curation
      - Writing
    affiliation: NOVA IMS
  - name: Fernando Bacao
    role:
      - Conceptualization
      - Supervision
      - Project administration
    affiliation: NOVA IMS
bibliography: references.bib
keywords:
  - Machine Learning Classification
  - Imbalanced Learning
  - Oversampling
  - Geometric SMOTE
  - Scikit-Learn
abstract: >
  Learning from class-imbalanced data continues to be a frequent and challenging problem in machine learning. Standard
  classification algorithms are designed under the assumption that the distribution of classes is balanced. To mitigate this problem
  several approaches have been proposed. The most general and popular approach is the generation of artificial data for the minority
  classes, known as oversampling. Geometric SMOTE is a state-of-the-art oversampling algorithm that has been shown to outperform
  other standard oversamplers in a large number of datasets. In order to make available Geometric SMOTE to the machine learning
  community, in this paper we provide a Python implementation. It is important to note that this implementation integrates
  seamlessly with the Scikit-Learn ecosystem. Therefore, machine learning researchers and practitioners can benefit from its use in
  a straightforward manner.
---

# Introduction

The imbalanced learning problem is defined as a machine learning classification task using datasets with binary or multi-class
targets where one of the classes, called the majority class, outnumbers significantly the remaining classes, called the minority
class(es) [@chawla_editorial_2004]. Learning from imbalanced data is a frequent and non-trivial problem for academic researchers
and industry practitioners alike. The imbalance learning problem can be found in multiple domains such as chemical and biochemical
engineering, financial management, information technology, security, business, agriculture or emergency management
[@haixiang_learning_2017].

Standard machine learning classification algorithms induce a bias towards the majority class during training. This results in low
performance when metrics suitable for imbalanced data are used for the classifier's evaluation. An important characteristic of
imbalanced data is the Imbalance Ratio ($IR$) which is defined as the ratio between the number of samples of the majority class
and each of the minority classes. For example, in a fraud detection task with 1% of fraudulent transactions, corresponding to an
$IR=\frac{0.99}{0.01}=99$, a trivial classifier that always labels a transaction as legit will score a classification accuracy of
$99%$. However in this case, all fraud cases remain undetected. $IR$ values between $100$ and $100.000$ have been observed
[@chawla_smote_2002], [@barua_mwmote--majority_2014]. Figure @fig-imbalanced-problem shows an example of imbalanced data in two
dimensions and the resulting decision boundary of a typical classifier when they are used as a training set.

![Imbalanced data in two dimensions. The decision boundary of a classifier shows a bias towards the majority
class.](imbalanced_problem.png){#fig-imbalanced-problem}

In [Theoretical background](#theoretical-background) section various concepts related to oversampling are presented, while in
[Implementation and architecture](#implementation-and-architecture) section a description of the software's implementation and
architecture is presented.

# Theoretical background

Various approaches have been proposed to deal with the imbalanced learning problem. The most general approach is the modification
at the data level by oversampling the minority class(es) [@fernandez_analysing_2013]. Synthetic Minority Oversampling Technique
(SMOTE) was the first informed oversampling algorithm proposed and continuous to be extensively used  [@chawla_smote_2002]. It
generates synthetic instances along a line segment that joins minority class samples. Although SMOTE has been shown to be
effective for generating artificial data, it also has some weaknesses [@haibo_he_learning_2009]. In order to improve the quality
of the generated data, many variants of SMOTE have been proposed. Nevertheless, all of these variations use the same data
generation mechanism, i.e. linear interpolation between minority class samples.

The Geometric SMOTE (G-SMOTE) oversampling algorithm [@douzas_geometric_2019] uses a different approach compared to existing
SMOTE's variations. More specifically, G-SMOTE oversampling algorithm substitutes the data generation mechanism of SMOTE by
defining a flexible geometric region around each minority class instance and generating synthetic instances inside the boundaries
of this region. The algorithm requires the selection of the hyperparameters `truncation_factor` , `deformation_factor`,
`selection_strategy` and `k_neighbors`. The first three of them, called geometric hyperparameters, control the shape of the
geometric region while the later adjusts its size. Figure @fig-smote-vs-gsmote presents a visual comparison between the data
generation mechanisms of SMOTE and G-SMOTE.

![Comparison between the data generation mechanisms of SMOTE and G-SMOTE. SMOTE uses linear interpolation, while G-SMOTE defines a
circle as the permissible data generation area.](smote_vs_gsmote.png){#fig-smote-vs-gsmote}

A Python implementation of SMOTE and several of its variants is available in the
[Imbalanced-Learn](https://imbalanced-learn.org/stable/) library [@lemaitre_imbalanced-learn_2016], which is fully compatible with
the popular machine learning toolbox [Scikit-Learn](https://scikit-learn.org/stable/) [@pedregosa_scikit-learn_2012]. In this
paper, we present `geometric-smote` a Python implementation of G-SMOTE.

# Implementation and architecture

The `geometric-smote` software project software project is compatible with Python 3.10 or greater. It contains an object-oriented
implementation of the G-SMOTE algorithm as well as an extensive [online documentation](https://geometric-smote.readthedocs.io/).
The implementation provides an API that is compatible with Imbalanced-Learn and Scikit-Learn libraries, therefore it makes full
use of various features that support standard machine learning functionalities.

The `geometric-smote` project contains the Python package `gsmote`. The main module of `gsmote` is called `geometric-smote.py`. It
contains the class `GeometricSMOTE` that implements the G-SMOTE algorithm. The initialization of a `GeometricSMOTE` instance
includes G-SMOTE's hyperparameters that control the generation of synthetic data. Additionally, `GeometricSMOTE` inherits from the
`BaseOverSampler` class of Imbalanced-Learn library. Therefore, an instance of `GeometricSMOTE` class provides the `fit` and
`fit_resample` methods, the two main methods for resampling as explained in subsection. This is achieved by implementing the
`fit_resample` abstract method of the parent class `BaseOverSampler`. More specifically, the function `_make_geometric_sample`
implements the data generation mechanism of G-SMOTE as shortly described in subsection. This function is called in the
`_make_geometric_samples` method of the `GeometricSMOTE` class in order to generate the appropriate number of synthetic data for a
particular minority class. Finally, the method `_make_geometric_samples` is called in `_fit_resample` method to generate synthetic
data for all minority classes. Figure 3 provides a visual representation of the above classes and functions hierarchy.

<figure><img src=":/9719d8354dbd4bd784a620d3c20a1a53" alt="" width="1211"
height="681" class="jop-noMdConv"><figcaption>UML class diagrams and callgraphs
of main classes and methods.</figcaption></figure>

# Software Functionalities

As it was mentioned in subsection, the class `GeometricSMOTE` represents the
G-SMOTE oversampler. The intializer of `GeometricSMOTE` includes the following
G-SMOTE's hyperparameters: `truncation_factor`, `deformation_factor`,
`selection_strategy` and `k_neighbors` as explained in subsection. Once the
`GeometricSMOTE` object is initialized with a specific parametrization, it can
be used to resample the imbalanced data represented by the input matrix `X` and
the target labels `y`. Following the Scikit-Learn API, both `X`, `y` are
array-like objects of appropriate shape.

Resampling is achieved by using the two main methods of `fit` and `fit_resample`
of the `GeometricSMOTE` object. More specifically, both of them take as input
parameters the `X` and `y`. The first method computes various statistics which
are used to resample `X` while the second method does the same but additionally
returns a resampled version of `X` and `y`.

The `geometric-smote` project has been designed to integrate with the
Imbalanced-Learn toolbox and Scikit-Learn ecosystem. Therefore the
`GeometricSMOTE` object can be used in a machine learning pipeline, through
Imbalanced-Learn's class `Pipeline`, that automatically combines `samplers`,
`transformers` and `estimators`. The next section provides examples of the above
functionalities.

# Usage examples

## Basic example

An example of resampling multi-class imbalanced data using the `fit_resample`
method is presented in Listing 1. Initially, a 3-class imbalanced dataset is
generated. Next, `GeometricSMOTE` object is initialized with default values for
the hyperparameters, i.e. `truncation_factor=1.0`, `deformation_factor=0.0`,
`selection_strategy='combined'`. Finally, the object's `fit_resample` method is
used to resample the data. Printing the class distribution before and after
resampling confirms that the resampled data `X_res`, `y_res` are perfectly
balanced. `X_res`, `y_res` can be used as training data for any classifier in
the place of `X`, `y`.

```python # Import classes and functions.

from collections import Counter from gsmote import GeometricSMOTE from
sklearn.datasets import make_classification

# Generate an imbalanced 3-class dataset.

X, y = make_classification( random_state=23, n_classes=3, n_informative=5,
n_samples=500, weights=\[0.8, 0.15, 0.05\] )

# Create a GeometricSMOTE object with default hyperparameters.

gsmote = GeometricSMOTE(random_state=10)

# Resample the imbalanced dataset.

X\_res, y\_res = gsmote.fit_resample(X, y)

# Print number of samples per class for initial and resampled data.

init_count = list(Counter(y).values()) resampled\_count =
list(Counter(y\_res).values())

print(f'Initial class distribution: {init_count}.')

# Initial class distribution: \[400, 75, 25\].

print(f'Resampled class distribution: {resampled_count}.')

# Resampled class distribution: \[400, 400, 400\]. ```

## Machine learning pipeline

As mentioned before, the `GeometricSMOTE` object can be used as a part of a
machine learning pipeline. Listing \\ref{lst:pipeline} presents a pipeline
composed by a G-SMOTE oversampler, a PCA tranformation and a decision tree
classifier. The pipeline is trained on imbalanced binary-class data and
evaluated on a hold-out set. The user applies the process in a simple way while
the internal details of the calculations are hidden.

```python # Import classes and functions.

from gsmote import GeometricSMOTE from sklearn.datasets import
make_classification from sklearn.decomposition import PCA from sklearn.tree
import DecisionTreeClassifier from sklearn.model\_selection import
train\_test_split from sklearn.metrics import f1_score from imblearn.pipeline
import make_pipeline

# Generate an imbalanced binary-class dataset.

X, y = make_classification( random_state=23, n_classes=2, n_samples=500,
weights=\[0.8, 0.2\] )

# Split the data to training and hold-out sets.

X\_train, X\_test, y\_train, y\_test = train\_test\_split(X, y, random_state=0)

# Create the pipeline's objects with default hyperparameters.

gsmote = GeometricSMOTE(random_state=11) pca = PCA() clf =
DecisionTreeClassifier(random_state=3)

# Create the pipeline.

pip = make_pipeline(gsmote, pca, clf)

# Fit the pipeline to the training set.

pip.fit(X\_train, y\_train)

# Evaluate the pipeline on the hold-out set using the F-score.

test\_score = f1\_score(y\_test, pip.predict(X\_test))

print(f'F-score on hold-out set: {test_score}.')

# F-score on hold-out set: 0.7. ```

# Quality control

All functions and classes have been tested for functionality and usability. These tests are integrated into the GitHub Actions
continuous integration (CI) service and they are automatically run each time new commits are pushed to GitHub using all supported
operating systems and Python versions. Checks in code quality, vulnerabilities in dependencies and type annotations are applied
through external libraries. Various development scripts that automate the above tasks are provided and described in detail in the
Contributing section of the online documentation and Github.

# Availability

## Operating system

Any system (GNU/Linux, Mac OSX, Windows) capable of running Python ≥ 3.10.

## Programming language

Python 3.10, or higher.

### Dependencies

- scipy >= 1.7.2
- numpy >= 1.22
- scikit-learn >= 1.1.1
- imbalanced-learn >= 0.9.0

### List of contributors

The software was created by Georgios Douzas.

### Software location

#### Zenodo

- **Name:** cluster-over-sampling
- **Persistent identifier:** https://doi.org/10.5281/zenodo.3370372
- **Licence:** MIT License
- **Publisher:**  Zenodo
- **Version published:** 0.4.0
- **Date published:** 01/10/2021

#### GitHub

- **Name:** cluster-over-sampling
- **Persistent identifier:** https://github.com/georgedouzas/cluster-over-sampling
- **Licence:** MIT
- **Date published:** 01/10/2021

### Language

English

# Reuse potential

Classification of imbalanced datasets is a challenging task for standard machine learning algorithms. G-SMOTE, as a enhancement of
the SMOTE data generation mechanism, provides a flexible and effective way for resampling the imbalanced data. G-SMOTE's emprical
results prove that it outperforms SMOTE and its variants. Machine learning researchers and industry practitioners can benefit from
using G-SMOTE in their work since the imbalanced learning problem is a common characteristic of many real-world applications.

The `geometric-smote` project provides the only Python implementation, to the best of our knowledge, of the state-of-the-art
oversampling algorithm G-SMOTE. A significant advantage of this implementation is that it is built on top of the Scikit-Learn's
ecosystem. Therefore, using the G-SMOTE oversampler in typical machine learning workflows is an effortless task for the user.
Also, the public API of the main class `GeometricSMOTE` is identical to the one implemented in Imbalanced-Learn for all
oversamplers. This means that users of Imbalanced-Learn and Scikit-Learn, that apply oversampling on imbalanced data, can
integrate the `gsmote` package in their existing work in a straightforward manner or even replace directly any Imbalanced-Learn's
oversampler with `GeometricSMOTE`.

# Funding statement

Funding: This research was supported by a grant from the Portuguese Foundation for Science and Technology (“Fundação para a
Ciência e a Tecnologia”), DSAIPA/DS/0116/2019.

# Competing interests

The authors declare that they have no competing interests.
